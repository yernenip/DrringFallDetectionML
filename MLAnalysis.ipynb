{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6eabd1-bf38-44fb-853e-f78737350840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset size: 819403\n",
      "Test Dataset size: 354166\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "files_path = 'imu-dataset-processed\\combine'\n",
    "# Path to folder containing Excel files\n",
    "folder_path = os.path.join(os.getcwd(), files_path)\n",
    "\n",
    "# Get a list of all files in the folder with a .xlsx extension\n",
    "excel_files = [file for file in os.listdir(folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "# Shuffle the list of Excel files randomly\n",
    "random.shuffle(excel_files)\n",
    "\n",
    "# Split the list of files into training and test sets\n",
    "train_files, test_files = train_test_split(excel_files, test_size=0.3, random_state=42)  # Adjust test_size as needed\n",
    "\n",
    "# Initialize empty lists for training and test sets\n",
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "# Load the files into the respective sets\n",
    "for file in train_files:\n",
    "    df = pd.read_excel(os.path.join(folder_path, file))\n",
    "    train_data = pd.concat([train_data, df], ignore_index=True)\n",
    "\n",
    "for file in test_files:\n",
    "    df = pd.read_excel(os.path.join(folder_path, file))\n",
    "    test_data = pd.concat([test_data, df], ignore_index=True)\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X_train = train_data.drop(columns=['Fall'])  \n",
    "y_train = train_data['Fall']\n",
    "\n",
    "X_test = test_data.drop(columns=['Fall'])\n",
    "y_test = test_data['Fall']\n",
    "\n",
    "print(f'Train Dataset size: {X_train.shape[0]}')\n",
    "print(f'Test Dataset size: {X_test.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dcbcb8-a89a-4302-a283-adcd2660f8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9979\n",
      "\n",
      "Confusion Matrix:\n",
      "[[352449    373]\n",
      " [   388    956]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00    352822\n",
      "        True       0.72      0.71      0.72      1344\n",
      "\n",
      "    accuracy                           1.00    354166\n",
      "   macro avg       0.86      0.86      0.86    354166\n",
      "weighted avg       1.00      1.00      1.00    354166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_report_str = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('\\nConfusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775d828a-d5d0-44b4-b011-a6a0a70eefc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\prave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "25607/25607 [==============================] - 32s 1ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0057 - val_accuracy: 0.9979\n",
      "Epoch 2/10\n",
      "25607/25607 [==============================] - 31s 1ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0066 - val_accuracy: 0.9978\n",
      "Epoch 3/10\n",
      "25607/25607 [==============================] - 31s 1ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.0061 - val_accuracy: 0.9975\n",
      "Epoch 4/10\n",
      "25607/25607 [==============================] - 31s 1ms/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.0052 - val_accuracy: 0.9981\n",
      "Epoch 5/10\n",
      "25607/25607 [==============================] - 31s 1ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.0066 - val_accuracy: 0.9979\n",
      "Epoch 6/10\n",
      "25607/25607 [==============================] - 31s 1ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.0055 - val_accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "25607/25607 [==============================] - 31s 1ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0068 - val_accuracy: 0.9980\n",
      "Epoch 8/10\n",
      "25607/25607 [==============================] - 30s 1ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 9/10\n",
      "25607/25607 [==============================] - 31s 1ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 10/10\n",
      "25607/25607 [==============================] - 32s 1ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0067 - val_accuracy: 0.9977\n",
      "11068/11068 [==============================] - 10s 871us/step - loss: 0.0067 - accuracy: 0.9977\n",
      "Accuracy: 0.9977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Standardize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c307af3d-035c-4c3b-8be0-e1dff547d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "\n",
    "# Convert the Keras model to ONNX format\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model)\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "with open(\"fall_detection_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48b487f3-4d56-4fb2-8647-33e5c0321916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.56349801e+00 -4.08240360e-01 -5.81008884e-02  3.28579281e-01\n",
      " -6.95715457e-02 -1.15181788e-01  1.03769525e-01 -7.49889381e-01\n",
      "  4.19225274e-01  5.41143190e-02 -2.27368507e-01  2.87148854e-04\n",
      " -1.23796903e-02  3.95544809e-03 -3.03909330e-01]\n",
      "Predicted class for record 0: 0\n",
      "Predicted class for record 1: 0\n",
      "Predicted class for record 2: 0\n",
      "Predicted class for record 3: 0\n",
      "Predicted class for record 4: 0\n",
      "Predicted class for record 5: 0\n",
      "Predicted class for record 6: 0\n",
      "Predicted class for record 7: 0\n",
      "Predicted class for record 8: 0\n",
      "Predicted class for record 9: 0\n",
      "Predicted class for record 10: 0\n",
      "Predicted class for record 11: 0\n",
      "Predicted class for record 12: 0\n",
      "Predicted class for record 13: 0\n",
      "Predicted class for record 14: 0\n",
      "Predicted class for record 15: 0\n",
      "Predicted class for record 16: 0\n",
      "Predicted class for record 17: 0\n",
      "Predicted class for record 18: 0\n",
      "Predicted class for record 19: 0\n",
      "Predicted class for record 20: 0\n",
      "Predicted class for record 21: 0\n",
      "Predicted class for record 22: 0\n",
      "Predicted class for record 23: 0\n",
      "Predicted class for record 24: 0\n",
      "Predicted class for record 25: 0\n",
      "Predicted class for record 26: 0\n",
      "Predicted class for record 27: 0\n",
      "Predicted class for record 28: 0\n",
      "Predicted class for record 29: 0\n",
      "Predicted class for record 30: 0\n",
      "Predicted class for record 31: 0\n",
      "Predicted class for record 32: 0\n",
      "Predicted class for record 33: 0\n",
      "Predicted class for record 34: 0\n",
      "Predicted class for record 35: 0\n",
      "Predicted class for record 36: 0\n",
      "Predicted class for record 37: 0\n",
      "Predicted class for record 38: 0\n",
      "Predicted class for record 39: 0\n",
      "Predicted class for record 40: 0\n",
      "Predicted class for record 41: 0\n",
      "Predicted class for record 42: 0\n",
      "Predicted class for record 43: 0\n",
      "Predicted class for record 44: 0\n",
      "Predicted class for record 45: 0\n",
      "Predicted class for record 46: 0\n",
      "Predicted class for record 47: 0\n",
      "Predicted class for record 48: 0\n",
      "Predicted class for record 49: 0\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "# Prepare sample input data\n",
    "onnx_model_path = \"fall_detection_model.onnx\"\n",
    "onnx_session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "\n",
    "print(X_test[76])\n",
    "\n",
    "input_data = X_test[50:100].astype(np.float32)\n",
    "input_data = input_data.reshape((-1, input_data.shape[-1]))\n",
    "\n",
    "# Perform inference\n",
    "output = onnx_session.run(None, {'dense_input': input_data})  # Replace 'dense_input' with the actual input name\n",
    "\n",
    "\n",
    "# Process output\n",
    "for i in range(50):\n",
    "    predicted_class = np.argmax(output[0][i])\n",
    "    print(f\"Predicted class for record {i}: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24bb87-8675-40fa-be5d-3e992260317c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
